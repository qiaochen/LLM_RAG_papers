### Representation editing

-  Wu, Z., Arora, A., Wang, Z., Geiger, A., Jurafsky, D., Manning, C. D., & Potts, C. (2024). [ReFT: Representation Finetuning for Language Models](https://arxiv.org/abs/2404.03592). _arXiv preprint arXiv:2404.03592_.


### [Knowledge editing](https://github.com/zjunlp/KnowledgeEditingPapers)



### Embedding
[MTEB leaderboard](https://huggingface.co/spaces/mteb/leaderboard)


- [LLM2Vec: Large Language Models Are Secretly Powerful Text Encoders](https://arxiv.org/abs/2404.05961)
> Very nice paper taught me how to transform a decoder-only LLM to bidirectional encoder. The gap between a decoder-only LLM and a good encoder is the attention mechanism: decoder-only means causal attention (a token's representation is generated by attending its prior tokens); for a encoder, both prior and future context should be exploited for a better representation.
> This work's strategy: 1) convert causal attention mask to non-causal; 2) fine tune with bidirectional next token prediction (a token be predicted using its previous and future token context, separately in loss computation, but together; they use next-to current token's representation to align with pretraining objective); 3) sentence level contrastive learning for overall text representation.
> Apart from top performance, their model analysis also show interesting model behaviors, especially for Mistral 7B chat. They  

<!--stackedit_data:
eyJoaXN0b3J5IjpbLTE4OTg0NDg2NTMsLTY5ODk4NzQ3NywtMj
AxMjYwMzIwMSwtNDU3NTQ2NDAyLC0xMDA4NDAzMDQxXX0=
-->