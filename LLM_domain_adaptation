### Representation editing

-  Wu, Z., Arora, A., Wang, Z., Geiger, A., Jurafsky, D., Manning, C. D., & Potts, C. (2024). [ReFT: Representation Finetuning for Language Models](https://arxiv.org/abs/2404.03592). _arXiv preprint arXiv:2404.03592_.


### [Knowledge editing](https://github.com/zjunlp/KnowledgeEditingPapers)



### Embedding
[MTEB leaderboard](https://huggingface.co/spaces/mteb/leaderboard)


- [LLM2Vec: Large Language Models Are Secretly Powerful Text Encoders](https://arxiv.org/abs/2404.05961)
> Very nice paper taught me how to transform a decoder-only LLM to bidirectional encoder. There are two

<!--stackedit_data:
eyJoaXN0b3J5IjpbMTQ5Mzc2NzUxMCwtNjk4OTg3NDc3LC0yMD
EyNjAzMjAxLC00NTc1NDY0MDIsLTEwMDg0MDMwNDFdfQ==
-->