#### Keywords:
- Large Language Models (LLM): 
	- Decoder-only Transformers, e.g. GPT and its extensions
	- Encoder-only Transformers, e.g., BERT and its extensions
	- Complete Transformers with both encoder and decoders, e.g., [BART](https://arxiv.org/abs/1910.13461), [T-5](https://arxiv.org/abs/1910.10683)
	- Beyond the Transformer architecture: Mamba
- Retrieval-augmented generation (RAG): 
- Fine tuning
- Instruct fine tuning


<!--stackedit_data:
eyJoaXN0b3J5IjpbLTc3MTg3Nzk4MSwxODc4MDE1NzU2LC0yMD
g4NzQ2NjEyXX0=
-->