#### Keywords:
- Large Language Models (LLM): 
	- Transformer architecture-based:
		- Decoder-only Transformers, e.g. GPT and its extensions
		- Encoder-only Transformers, e.g., BERT and its extensions
		- Complete Transformers with both encoder and decoders, e.g., [BART](https://arxiv.org/abs/1910.13461), [T-5](https://arxiv.org/abs/1910.10683)
	- [Mamba](https://arxiv.org/abs/2312.00752)
		
- Retrieval-augmented generation (RAG): 
- Fine tuning
- Instruct fine tuning


<!--stackedit_data:
eyJoaXN0b3J5IjpbLTE0MTc0Nzg2NzAsMTg3ODAxNTc1NiwtMj
A4ODc0NjYxMl19
-->