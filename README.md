#### Keywords:
- Large Language Models (LLM): 
	- [Transformer](https://arxiv.org/abs/1706.03762) architecture-based:
		- Decoder-only Transformers, e.g. GPT and its extensions
		- Encoder-only Transformers, e.g., BERT and its extensions
		- Complete Transformers with both encoder and decoders, e.g., [BART](https://arxiv.org/abs/1910.13461), [T-5](https://arxiv.org/abs/1910.10683)
	- [Mamba](https://arxiv.org/abs/2312.00752)
		
- Retrieval-augmented generation (RAG): 
- Fine tuning
- Instruct fine tuning


<!--stackedit_data:
eyJoaXN0b3J5IjpbLTEwNDIxNzA4ODYsMTg3ODAxNTc1NiwtMj
A4ODc0NjYxMl19
-->